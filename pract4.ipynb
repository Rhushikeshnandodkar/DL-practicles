{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'this is a sample sentence',\n",
    "    'another example for training this',\n",
    "    'one more sentence to use'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 1,\n",
       " 'sentence': 2,\n",
       " 'is': 3,\n",
       " 'a': 4,\n",
       " 'sample': 5,\n",
       " 'another': 6,\n",
       " 'example': 7,\n",
       " 'for': 8,\n",
       " 'training': 9,\n",
       " 'one': 10,\n",
       " 'more': 11,\n",
       " 'to': 12,\n",
       " 'use': 13}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 4, 5, 2], [6, 7, 8, 9, 1], [10, 11, 2, 12, 13]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 2\n",
    "vocab_size = len(word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for sequence in sequences:\n",
    "    for i in range(window_size, len(sequence) - window_size):\n",
    "        context = sequence[i-window_size : i] + sequence[i + 1: i+window_size + 1]\n",
    "        target = sequence[i]\n",
    "        x.append(context)\n",
    "        y.append(target)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pad_sequences(x, maxlen=window_size * 2)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  3,  5,  2],\n",
       "        [ 6,  7,  9,  1],\n",
       "        [10, 11, 12, 13]]),\n",
       " array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "cbow_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726ms/step - accuracy: 0.0000e+00 - loss: 2.6442\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 2.6302\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 2.6162\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6667 - loss: 2.6022\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5882\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5741\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.5601\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.5460\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.5318\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5175\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.5032\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.4888\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.4742\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4595\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.4447\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4297\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.4146\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.3993\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.3838\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3681\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3522\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.3361\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3198\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.3032\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.2864\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.2693\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.2520\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.2344\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.2165\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.1984\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1800\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.1613\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.1423\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.1230\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.1034\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.0835\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.0632\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.0427\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.0219\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.0008\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9794\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.9577\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9356\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.9133\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.8907\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.8678\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8446\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.8212\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.7974\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.7734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bc622a9010>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cbow_model.fit(x, y, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02034006,  0.02028139, -0.00767187, ...,  0.01988966,\n",
       "         0.00768151,  0.04152813],\n",
       "       [-0.0165398 , -0.10300218,  0.00352357, ..., -0.04473084,\n",
       "         0.02086291,  0.06858039],\n",
       "       [-0.03676633, -0.0352583 , -0.09978631, ..., -0.02732353,\n",
       "        -0.09604567,  0.01697694],\n",
       "       ...,\n",
       "       [ 0.02351741,  0.00710142, -0.01570841, ..., -0.03511023,\n",
       "         0.01374175, -0.04615513],\n",
       "       [ 0.07754136,  0.08705931, -0.01785648, ..., -0.05017237,\n",
       "         0.06452472, -0.06641962],\n",
       "       [ 0.06263565,  0.08489707, -0.02448575, ..., -0.0762534 ,\n",
       "         0.09344567, -0.0021745 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights = cbow_model.layers[0].get_weights()[0]\n",
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: this, embedding: [-0.0165398  -0.10300218  0.00352357  0.08929167 -0.08683573 -0.02687878\n",
      "  0.09003623 -0.02927724  0.00042969  0.10610063  0.09181257  0.09040575\n",
      " -0.02917653  0.01803196  0.03734789 -0.0067294   0.0266013  -0.01091461\n",
      " -0.09764872 -0.01108759 -0.06140157  0.09965797 -0.05650276  0.02297851\n",
      "  0.01204668  0.08688913 -0.10037839  0.03155684 -0.11560455 -0.02746874\n",
      " -0.10044873  0.00446534  0.04945168 -0.07362105 -0.00176368  0.05969793\n",
      "  0.0816465  -0.02665667  0.02867062 -0.02575292 -0.0613834   0.04748626\n",
      " -0.07207133  0.0174475   0.06124455  0.04743626 -0.02872558 -0.06806921\n",
      "  0.01825881  0.03421443  0.05353619  0.00813287 -0.04954229 -0.00944204\n",
      " -0.05853362 -0.06568462  0.07945254  0.0508744  -0.1060519  -0.00828628\n",
      "  0.06593474  0.00989058  0.02690917 -0.06929731  0.05021228 -0.02242985\n",
      "  0.09814024 -0.06261732 -0.00508583 -0.07304005 -0.02715414  0.09467049\n",
      " -0.03456342 -0.03928822 -0.02872525 -0.0095884  -0.01622641  0.05052416\n",
      "  0.02979689 -0.0529125  -0.04143534  0.05460552 -0.09515243  0.05238226\n",
      "  0.05672638 -0.05014532  0.07275005 -0.06202805  0.05322061 -0.06227304\n",
      " -0.0389691   0.02880956  0.01176095  0.07914659 -0.05941853 -0.00307827\n",
      " -0.0241727  -0.04473084  0.02086291  0.06858039]\n",
      "word: sentence, embedding: [-0.03676633 -0.0352583  -0.09978631  0.04092226 -0.07870792 -0.09741588\n",
      "  0.07664698 -0.00722583  0.02539456  0.09415903  0.02029209  0.03384805\n",
      " -0.02384871  0.01035107  0.01895006 -0.05720471  0.06958131 -0.02493094\n",
      " -0.09445059 -0.06245663  0.04933223  0.03008587  0.07480016 -0.03482385\n",
      " -0.00165539 -0.04046863 -0.06044733  0.0316685  -0.06986253  0.03496026\n",
      " -0.00903873 -0.0367756  -0.03285034 -0.10052381 -0.00981498  0.0400369\n",
      "  0.00491674 -0.00513336  0.03770333  0.00686927 -0.02390022  0.03133907\n",
      "  0.03060885  0.09097934  0.04400953 -0.04266845  0.08085458 -0.06618723\n",
      "  0.08364626  0.08504932  0.07893047 -0.01817167 -0.01720674  0.00952959\n",
      " -0.08200803 -0.03800569  0.03529352  0.01128421 -0.00726312  0.09289955\n",
      "  0.06051747  0.04454228 -0.049505   -0.04110081  0.07125758 -0.03328898\n",
      "  0.05703819 -0.06353443 -0.05515696 -0.09217938 -0.02954701  0.02673283\n",
      "  0.0976456  -0.08801849 -0.05293352 -0.09110066  0.08963471  0.06893061\n",
      " -0.04603843  0.09233333  0.08375493  0.09678762 -0.02183183 -0.03284416\n",
      "  0.08268885 -0.09392161  0.0650254  -0.03533212  0.08050998 -0.09112551\n",
      " -0.02115723  0.05489554 -0.0790276   0.10082576 -0.09980045  0.02339615\n",
      " -0.03268731 -0.02732353 -0.09604567  0.01697694]\n",
      "word: is, embedding: [-0.05579897 -0.09414323 -0.05009147  0.00976201 -0.06025872 -0.0419283\n",
      "  0.02345721 -0.00863962  0.00788878  0.07674437  0.00463092  0.10065735\n",
      " -0.09936269  0.09619481  0.01008927 -0.0206883   0.09932839 -0.00894062\n",
      " -0.01934995 -0.02722749  0.06527553  0.01784705  0.03124892 -0.02916856\n",
      " -0.07090176 -0.0500363  -0.03524217  0.00658968 -0.04944417  0.01973603\n",
      " -0.05604447 -0.07234543 -0.01362607 -0.04883271 -0.07303496  0.06841025\n",
      "  0.00593947 -0.02559498  0.00468973  0.03184704 -0.09465904  0.03802341\n",
      "  0.04773746  0.10246504  0.05922739 -0.01375571  0.09598295 -0.0441944\n",
      "  0.05703263  0.08789558  0.09131189 -0.08280595 -0.0128598  -0.06224315\n",
      " -0.00361618 -0.09918291  0.08883299 -0.03964435 -0.00185811  0.06501637\n",
      "  0.09728353  0.05745533 -0.04429269 -0.05769837  0.04424644 -0.02262623\n",
      "  0.10177352 -0.04450948 -0.05845068 -0.04509207 -0.04934299  0.00222248\n",
      "  0.07974245 -0.01566073 -0.08499552 -0.0269611   0.04424652  0.09366317\n",
      " -0.08387098  0.08379035  0.05658685  0.03692501 -0.07942302 -0.07905158\n",
      "  0.01366738 -0.09747814  0.03988501 -0.08126279  0.07394985 -0.04342548\n",
      " -0.06940166  0.0805071  -0.04492769  0.0777865  -0.05076025  0.01516744\n",
      " -0.06147967 -0.09475271 -0.02728359  0.08859691]\n",
      "word: a, embedding: [ 0.02778158  0.02488678 -0.0496769  -0.0119545  -0.03355833 -0.04944814\n",
      " -0.03974969 -0.00287171 -0.03202685 -0.04137232 -0.00640579 -0.04524824\n",
      "  0.04302825 -0.00438241  0.01051413  0.03263019  0.04988683 -0.00312784\n",
      "  0.00082295  0.00663107  0.00872362  0.03926697  0.04844842  0.030691\n",
      "  0.00234988  0.01183437 -0.00470086  0.00770391  0.02332674 -0.0123684\n",
      " -0.03939345 -0.01559902 -0.0157076   0.02066258  0.00280359 -0.03817794\n",
      " -0.01679779  0.04151007 -0.03067946  0.04822666  0.02863463  0.00214319\n",
      "  0.03157038  0.00117662 -0.02967315  0.03617297  0.01337608 -0.03621082\n",
      " -0.0421983  -0.02053384 -0.00584924  0.02139659 -0.0226921  -0.02240046\n",
      "  0.04788958  0.0040324   0.02726592  0.00874028  0.04796262 -0.00459925\n",
      "  0.04125324 -0.02116278 -0.00787045  0.0489707  -0.04810944 -0.02704972\n",
      "  0.02738695  0.01602224 -0.03219795  0.02147666  0.00934727  0.01211857\n",
      " -0.02335086 -0.00048999  0.02346538  0.04107041 -0.03538352  0.01113494\n",
      "  0.01504383  0.04577627  0.00931964  0.02423877 -0.04065358 -0.01224517\n",
      "  0.00783186 -0.0114331  -0.04885993 -0.04527024 -0.0363101   0.04963375\n",
      "  0.04483808 -0.01030425  0.02325454 -0.02350301  0.00500065  0.03909148\n",
      "  0.01518625 -0.04622679  0.0227606  -0.01540057]\n",
      "word: sample, embedding: [-5.95361069e-02 -1.84847452e-02 -4.17825691e-02  2.27808487e-02\n",
      " -6.62941635e-02 -2.85478681e-03  1.49286706e-02 -3.27768698e-02\n",
      "  6.39076158e-02  6.95397332e-02  7.93505535e-02  3.66250500e-02\n",
      " -5.82254641e-02  4.81128953e-02  8.72510374e-02 -7.21954778e-02\n",
      "  6.61313608e-02 -8.87230039e-02 -5.84635101e-02 -9.70759913e-02\n",
      "  3.58501785e-02  4.20809239e-02  3.71587463e-02 -2.35929117e-02\n",
      " -8.73083919e-02 -2.94403229e-02 -9.70441550e-02  8.57577920e-02\n",
      " -2.29254328e-02  3.37390453e-02 -5.53516038e-02 -5.22852615e-02\n",
      " -6.65339753e-02 -3.62106562e-02 -9.43291560e-02  4.27964032e-02\n",
      "  3.79852653e-02  5.36445878e-05  2.49069892e-02  7.00138509e-03\n",
      " -6.29258305e-02  2.61525605e-02  4.00182568e-02  2.15223506e-02\n",
      "  4.23699878e-02 -8.12941194e-02  8.33989084e-02 -8.18676353e-02\n",
      "  3.43197398e-02  5.33383898e-03  1.27364546e-02 -4.22067940e-02\n",
      " -7.82368034e-02 -1.23098865e-02 -5.20775318e-02 -1.00115925e-01\n",
      "  2.60594189e-02 -1.21709369e-02 -1.65666472e-02  1.77516676e-02\n",
      "  5.20398654e-02  6.44192621e-02 -1.00094534e-01 -6.37208670e-02\n",
      "  9.35591310e-02 -1.36105036e-02  9.73782316e-02 -7.48959258e-02\n",
      " -4.37156484e-02 -9.83881205e-02 -7.96703026e-02  8.26333314e-02\n",
      "  6.41983980e-03 -9.14704800e-02 -7.26128742e-02 -1.34487133e-02\n",
      "  8.77642408e-02  1.23227350e-02 -7.53319263e-02  4.82469499e-02\n",
      "  5.74411303e-02  6.06021062e-02 -9.70432237e-02 -2.88749505e-02\n",
      "  5.42011298e-02 -5.83099686e-02  9.59276222e-03 -3.23291216e-03\n",
      "  5.50908968e-02 -1.98545028e-02 -1.00771740e-01  4.13082205e-02\n",
      " -2.13859472e-02  4.73999418e-02 -4.28259224e-02 -2.54134997e-04\n",
      " -3.54914442e-02 -5.63680753e-02 -7.36429393e-02  3.22460122e-02]\n",
      "word: another, embedding: [-0.01897344 -0.05529661  0.10734487  0.03223593 -0.07891327 -0.08150807\n",
      "  0.01056728 -0.09074128 -0.10089867  0.07446718  0.08646044  0.06143047\n",
      "  0.05809442 -0.09948107  0.07647704  0.07089908 -0.01604127  0.09625027\n",
      " -0.07004043  0.04158369 -0.06965289  0.03850644 -0.00189542  0.0382679\n",
      "  0.0843837   0.07315122 -0.02722451  0.00527727 -0.09617916 -0.05667792\n",
      " -0.06814108  0.09880696  0.06873978  0.09452048  0.05796869  0.08745978\n",
      "  0.10114776 -0.0807028  -0.09570257 -0.04863153 -0.09089956  0.08431672\n",
      " -0.02250535 -0.06381159  0.04087149  0.00472604 -0.07622505 -0.09613816\n",
      " -0.07507776 -0.05614421  0.04116442  0.03801902  0.04199943  0.04215409\n",
      "  0.01156686  0.02116562  0.02214779  0.08338628 -0.08682971 -0.08566632\n",
      "  0.06182976 -0.07692871  0.07734934 -0.00728785 -0.02177968 -0.0680708\n",
      "  0.06957912 -0.07868712  0.10408946  0.09793833 -0.01309446  0.07321945\n",
      " -0.00857293 -0.03657351  0.077232    0.01018883 -0.08530152  0.06948325\n",
      "  0.04700825 -0.0230711  -0.08938766  0.00604533 -0.07220367  0.0697382\n",
      "  0.0315594   0.00809156  0.03111221 -0.01417703  0.09022809 -0.09228367\n",
      "  0.07509882 -0.08354548  0.06183395  0.09357687 -0.08232808 -0.07870872\n",
      " -0.05411894 -0.04162757  0.02402687 -0.09130713]\n",
      "word: example, embedding: [-0.00930097 -0.02937832  0.10143548  0.06235621 -0.02028644 -0.05243417\n",
      "  0.09336982 -0.03714533 -0.00794007  0.05591247  0.0476703   0.08162215\n",
      "  0.0521665  -0.09930793  0.07805705  0.01579298 -0.03865158  0.05329747\n",
      " -0.03906476  0.0826012  -0.05048544  0.08120599 -0.03555365  0.02690542\n",
      "  0.05374423  0.01667913 -0.03325055  0.0243568  -0.09613049 -0.06465383\n",
      " -0.06348623  0.04865946  0.10004304  0.08065436  0.10528801  0.07177892\n",
      "  0.05805231 -0.06557022 -0.04118985 -0.01219196 -0.03205354  0.07502846\n",
      " -0.02856584 -0.09287782  0.04856474  0.02394982 -0.05951004 -0.07796437\n",
      " -0.06685901 -0.01286322  0.0692689   0.03707176  0.04354205  0.02129787\n",
      "  0.01392857  0.08516186  0.08269528  0.00137665 -0.07969731 -0.06406239\n",
      "  0.08740076 -0.0298984   0.08345584 -0.05243074 -0.08075285 -0.04195652\n",
      "  0.05836898 -0.04516581  0.08559096  0.06511086  0.00011992  0.07950626\n",
      " -0.05770545 -0.0026872   0.08410624  0.00957912 -0.10016654  0.03518978\n",
      "  0.01334321 -0.04427693 -0.10007542  0.03505056 -0.0848095   0.03143796\n",
      "  0.05481616  0.03981462  0.0845502  -0.09744529  0.02763408 -0.06948033\n",
      "  0.0951215  -0.01186259  0.07745039  0.04813328 -0.09619414 -0.03487251\n",
      " -0.04862137 -0.09813449  0.09718834 -0.09993526]\n",
      "word: for, embedding: [ 0.00322652 -0.00965588  0.01137121 -0.00617198  0.03396576 -0.00760561\n",
      "  0.00589156  0.01108069 -0.03413439 -0.00017339  0.02512017 -0.01354513\n",
      " -0.02297227  0.00260944  0.01708658  0.00968864  0.02372    -0.01757048\n",
      " -0.02458405 -0.03065882  0.01641995 -0.0006381  -0.00448108  0.02723422\n",
      " -0.03152199 -0.0477509   0.03606386 -0.02437195  0.01602993 -0.03869698\n",
      "  0.02824265  0.00778202 -0.02943109 -0.00347244  0.01706144  0.02442045\n",
      "  0.00812221 -0.01879503  0.00269476 -0.04993587  0.01631618  0.0142698\n",
      " -0.00166502  0.03517338  0.01981347 -0.00605456  0.04237035  0.00998356\n",
      " -0.01878789 -0.02837609 -0.02836283 -0.03589841  0.01359699  0.00260538\n",
      " -0.00936519  0.03772918  0.01167823 -0.0196877  -0.00622867 -0.03186424\n",
      "  0.04781452  0.01176386 -0.0311415  -0.02764772  0.04311934 -0.0299139\n",
      " -0.00403041  0.0115738   0.01870929 -0.03175789  0.02025131 -0.00061346\n",
      "  0.00560241  0.04404119  0.00038996  0.01817688  0.02778811 -0.01397028\n",
      " -0.02753441  0.02376227 -0.03207242 -0.04412639  0.01421792 -0.03612738\n",
      "  0.00194596 -0.00859823  0.03189823  0.01659907 -0.03656467  0.04796958\n",
      " -0.01827586  0.04794823 -0.0078487   0.02143896 -0.03844328 -0.00316447\n",
      "  0.04137308 -0.01276474  0.03703815 -0.0174608 ]\n",
      "word: training, embedding: [-0.07300349 -0.07155877  0.07051281  0.0639343  -0.00516751 -0.096375\n",
      "  0.03730388 -0.09506722 -0.02455096  0.05738136  0.04916824  0.10224634\n",
      "  0.09568746 -0.07493205  0.05901874  0.09775861 -0.09846148  0.06180641\n",
      " -0.08040132  0.01896001 -0.05305151  0.06318819 -0.09913167  0.00024889\n",
      "  0.01293151  0.05141007 -0.0501336   0.07076795 -0.08398519 -0.05526104\n",
      " -0.04450203  0.03763389  0.01132051  0.02814749  0.05793531  0.08264682\n",
      "  0.0327734  -0.09733846 -0.04336637 -0.08382513 -0.10056465  0.10354824\n",
      " -0.04381255 -0.04000579  0.02061972  0.04023246 -0.07492094 -0.1022886\n",
      " -0.02370486 -0.07514184  0.09877346  0.06786089  0.0149911   0.04419043\n",
      "  0.02423231  0.02972798  0.00444902  0.00613481 -0.08932965 -0.08711335\n",
      "  0.02724739 -0.06069527  0.00737496 -0.09847222 -0.00360856 -0.10767153\n",
      "  0.08762948 -0.04812862  0.1048265   0.06478809 -0.032036    0.0865886\n",
      " -0.03656043 -0.02218845  0.0146243   0.02615154 -0.00689941  0.08036414\n",
      "  0.05742362 -0.06069235 -0.06858165  0.03424311 -0.05188951  0.00929656\n",
      "  0.00394427  0.09466439  0.09488605 -0.00232888  0.08657618 -0.09521524\n",
      "  0.04331565 -0.04801991  0.06006853  0.01396621 -0.07533989 -0.0500552\n",
      " -0.10077185 -0.09777975  0.09216292 -0.00316216]\n",
      "word: one, embedding: [ 0.07510863  0.07296422 -0.04172281  0.0035266   0.01302591  0.08015701\n",
      " -0.09631791 -0.09791707 -0.01601335 -0.05862344 -0.02733917 -0.09586988\n",
      " -0.0406956   0.03386213  0.02331646 -0.00736106  0.09833783  0.03714364\n",
      " -0.06972527 -0.07730498  0.08165155 -0.0874285  -0.02438168  0.05790029\n",
      " -0.01901964 -0.06922679 -0.05533205 -0.07113085  0.03348618 -0.0727729\n",
      " -0.1013361   0.07971349 -0.0586466  -0.01344178  0.01559353  0.02341\n",
      " -0.00926962 -0.09565663 -0.00846049  0.08330092  0.06208073  0.05301025\n",
      " -0.0367153   0.08802157 -0.06850988  0.00102501 -0.01307886 -0.03636328\n",
      " -0.02765895 -0.04604775  0.04248732  0.02609107  0.06665646 -0.08237474\n",
      " -0.05097461  0.09961769  0.07326952  0.06450687  0.1007615   0.05847257\n",
      "  0.05012912  0.10027285 -0.00445623 -0.02536561 -0.09127706 -0.03375871\n",
      "  0.04848254 -0.07270661  0.05265247  0.09068672  0.04240898 -0.005133\n",
      "  0.01116873  0.02360745  0.09724998 -0.01171019  0.0409922   0.08102044\n",
      "  0.00708699 -0.04672242  0.04533285  0.04420576 -0.09130885 -0.02259866\n",
      "  0.07577419 -0.03256917  0.06054338  0.09916824 -0.01029203 -0.04853055\n",
      " -0.09724282 -0.01000508 -0.00173589  0.07153333 -0.01679897  0.02898111\n",
      "  0.0730258  -0.02554593  0.0049144  -0.04611511]\n",
      "word: more, embedding: [ 2.3517406e-02  7.1014212e-03 -1.5708407e-02  7.9549635e-03\n",
      "  3.6409579e-02  5.0596245e-02 -2.3353364e-02 -3.9428458e-02\n",
      " -5.1467519e-02 -1.7912459e-02 -1.7766312e-02 -4.1502763e-02\n",
      " -5.8558583e-02  5.1861390e-02  6.4388677e-02 -5.8906481e-02\n",
      "  7.3186986e-02  3.2896390e-03 -3.2279398e-02 -2.4996093e-02\n",
      "  8.8352740e-02 -2.2066891e-02 -8.6959362e-02  9.4764516e-02\n",
      " -3.7484476e-03 -1.0295472e-02 -5.6464385e-02 -4.1727073e-02\n",
      "  8.3779484e-02 -4.5077678e-02 -7.4110433e-02  2.4705723e-02\n",
      " -3.8772725e-02 -5.8608543e-02  3.7124220e-03  9.1679625e-02\n",
      " -3.3875782e-02 -3.7260959e-03 -3.5904497e-02  3.7044972e-02\n",
      "  3.3272449e-03  8.3498538e-02 -4.9658507e-02  7.0121460e-02\n",
      " -6.7859307e-02  6.7755640e-02 -1.2355263e-02 -9.1596112e-02\n",
      " -1.5210693e-02 -6.1552089e-02  6.6631950e-02  8.5044473e-02\n",
      "  1.6939646e-02 -5.9155863e-02 -1.4291235e-02  4.8937369e-02\n",
      "  7.0819698e-02  7.5911902e-02  4.2396598e-02  3.1741135e-02\n",
      "  7.3443050e-05  8.7151319e-02 -7.5065628e-02 -8.4730133e-02\n",
      " -1.0230746e-01 -2.9929586e-02 -2.3119142e-03 -4.1060738e-02\n",
      "  4.8377622e-02  7.1151763e-02  5.9916873e-02 -9.9110387e-02\n",
      "  5.3329360e-02  3.2873910e-02  1.0465520e-01 -4.6665292e-02\n",
      "  2.7754651e-02  3.9725132e-02  9.7531348e-02 -9.4705842e-02\n",
      "  8.3686665e-02  4.4689752e-02 -2.3286408e-02 -7.4707875e-03\n",
      "  8.9035481e-02 -7.3380256e-03  7.2469309e-02  5.2006692e-02\n",
      " -4.1289128e-02 -3.3007026e-02 -2.0863174e-02 -2.3925717e-03\n",
      " -9.0925574e-02  5.1282872e-02 -4.8008442e-02 -2.1539759e-03\n",
      "  2.9431695e-02 -3.5110231e-02  1.3741747e-02 -4.6155129e-02]\n",
      "word: to, embedding: [ 0.07754136  0.08705931 -0.01785648  0.07186673  0.08378321  0.00584436\n",
      " -0.04889844 -0.02003513 -0.09010701 -0.01538665 -0.05668258 -0.03010348\n",
      " -0.10020958  0.07098535  0.08558149 -0.08280897  0.09520183  0.07062662\n",
      " -0.01001229 -0.05005397  0.01697467 -0.01624004 -0.09507409  0.08560982\n",
      " -0.00548743 -0.04613178 -0.05355179 -0.02484667  0.01019939 -0.09172266\n",
      " -0.0535571   0.02357137 -0.07788327 -0.10027096  0.00409046  0.05487476\n",
      " -0.06357125 -0.00525667 -0.09696969  0.06325806  0.02245123  0.06829727\n",
      " -0.02730402  0.03146078 -0.01138477  0.01318729 -0.00027788 -0.04224973\n",
      " -0.05529032 -0.03671334  0.01088018  0.00980976  0.0005856  -0.01093705\n",
      " -0.0255697   0.06356137  0.085628    0.06585483  0.08847174  0.06659285\n",
      "  0.04988557  0.08807634 -0.03810716 -0.01896382 -0.01533873 -0.10380907\n",
      "  0.00184041 -0.1041079   0.08665652  0.04921592  0.00270362 -0.07049642\n",
      "  0.04848679  0.07813719  0.06130012 -0.09989314  0.0767827   0.09740271\n",
      "  0.09928747 -0.07415613  0.04267238  0.07861303 -0.09183835 -0.05774846\n",
      "  0.0979901  -0.08865142  0.06723291  0.00804797 -0.09975797 -0.07427605\n",
      " -0.06380049  0.00799491 -0.05555816  0.03840456 -0.0115229  -0.0026756\n",
      "  0.01935956 -0.05017237  0.06452472 -0.06641962]\n",
      "word: use, embedding: [ 6.26356527e-02  8.48970711e-02 -2.44857520e-02  3.56204808e-02\n",
      "  3.02121416e-02  3.38925794e-02 -2.35624379e-03 -8.05683993e-03\n",
      " -2.00844277e-03 -9.27845016e-02 -2.26211008e-02 -2.76137926e-02\n",
      " -4.31537954e-03  5.55135012e-02  8.74175280e-02 -7.97243137e-03\n",
      "  6.23203851e-02  7.81951994e-02 -7.56421313e-02 -9.16022658e-02\n",
      "  4.89887781e-02 -7.21230656e-02 -1.77945811e-02  1.30832624e-02\n",
      "  3.23351147e-03 -9.31488648e-02 -8.73567685e-02 -3.39030661e-02\n",
      "  2.10445188e-02 -2.75878087e-02 -8.52425024e-02  5.47450669e-02\n",
      " -5.99293932e-02 -7.00612813e-02 -3.83278471e-03  4.35374267e-02\n",
      " -8.06107447e-02 -2.38641631e-03 -9.20426324e-02  1.29872859e-02\n",
      "  2.83745620e-02  2.66103111e-02 -7.32481033e-02  1.08225374e-02\n",
      " -1.01833187e-01  6.12977073e-02 -6.30975934e-03 -4.19741534e-02\n",
      " -2.58120429e-02 -5.32040745e-02  9.03056934e-02  4.04674299e-02\n",
      "  4.49365750e-02 -4.89580594e-02 -4.93642353e-02  6.53876364e-02\n",
      "  1.27567798e-02  1.58131737e-02  8.21488425e-02  6.15785457e-02\n",
      "  3.22662145e-02  9.62154474e-03 -2.10175794e-02 -1.01359785e-02\n",
      " -7.82617629e-02 -9.49841514e-02  3.48991156e-02 -4.29439284e-02\n",
      "  5.47470711e-02  2.57812664e-02  8.75207260e-02 -4.61630709e-03\n",
      "  1.01238072e-01  4.16352376e-02  8.55129883e-02 -9.66107100e-02\n",
      "  9.71297175e-02  1.03801444e-01  9.59378034e-02 -5.20048030e-02\n",
      "  6.46850169e-02  4.96618561e-02 -2.35607270e-02 -1.17658526e-02\n",
      "  6.16997899e-03 -3.16504389e-02  1.31466556e-02  1.61817800e-02\n",
      " -4.97775078e-02 -8.08881596e-02 -4.65777479e-02  2.27348506e-02\n",
      " -2.82221306e-02  2.08556205e-02 -8.55970979e-02  4.23660278e-02\n",
      "  6.71290909e-05 -7.62533993e-02  9.34456736e-02 -2.17449944e-03]\n"
     ]
    }
   ],
   "source": [
    "for word, index in word_index.items():\n",
    "    print(f'word: {word}, embedding: {embedding_weights[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
